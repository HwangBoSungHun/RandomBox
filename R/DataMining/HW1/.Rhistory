ylab="Gallons per 100 miles",
main="Cars(1993 Makes & Models)",pch=16))
# Modelling:  Cars and Fuel Economy
with(Cars93,xyplot(100/MPG.highway~Weight,
ylab="Gallons per 100 miles",pch=16,
main="Cars(1993 Makes & Models)",
panel =
function(x, y, ...) {
panel.xyplot(x, y, ...)
panel.lmline(x, y,col="red", ...)
}))
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
install.packages("data.table")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
getwd()
titanic <- read.csv("titanic.csv")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
library(data.table)
library(ggplot2)
titanic <- read.csv("titanic.csv")
#분석 편의상 data.table로 변환한다.
titanic.dt <- as.data.table(titanic)
names(titanic.dt)
head(titanic.dt)
titanic.dt$survived <- as.factor(titanic.dt$survived)
#15세 미만을 아이로 본다.
titanic.dt[,isminor:="adult"]
titanic.dt[age < 15,isminor:="child"]
titanic.dt$isminor <- as.factor(titanic.dt$isminor)
# 등급별 생존률
titanic.dt[, length(which(survived == 1))/nrow(.SD), by=pclass]
# 성별 생존률
titanic.dt[, length(which(survived == 1))/nrow(.SD), by=sex]
#등급/성별 생존률
survived_pclass_sex <- titanic.dt[, list(cntsurv=length(which(survived == 1)), cntdie=length(which(survived == 0))),
by=list(pclass, sex)][,list(psurvived=cntsurv/(cntsurv + cntdie)),by=list(pclass, sex)]
ggplot(survived_pclass_sex, aes(pclass, sex)) +
geom_tile(aes(fill=psurvived)) + scale_fill_gradient2("생존률") + xlab("승객등급") + ylab("성별")
#성별, 등급, 나이별 생존률
survived_pclass_sex_isminor<- titanic.dt[,list(cntsurv=length(which(survived == 1)), cntdie=length(which(survived == 0))),by=list(pclass, sex, isminor)][,list(psurvived=cntsurv/(cntsurv + cntdie)),by=list(pclass, sex, isminor)]
survived_pclass_sex_isminor$sex_age <- apply(survived_pclass_sex_isminor[,list(sex,isminor)], 1, paste, collapse="_")
library(scales)
ggplot(survived_pclass_sex_isminor, aes(pclass, sex_age)) +
geom_tile(aes(fill=psurvived)) + scale_fill_gradient2("생존률", low=muted("white"), high=muted("blue")) + xlab("승객등급") + ylab("성별과 나이")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
library(data.table)
library(ggplot2)
titanic <- read.csv("titanic.csv")
#분석 편의상 data.table로 변환한다.
titanic.dt <- as.data.table(titanic)
names(titanic.dt)
head(titanic.dt)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
titanic.dt[,isminor:="adult"]
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/Desktop/3-1/DataMining/R_reference_codes/Rscript_titanic.R', encoding = 'CP949', echo=TRUE)
library(data.table)
library(ggplot2)
titanic <- read.csv("titanic.csv")
#분석 편의상 data.table로 변환한다.
titanic.dt <- as.data.table(titanic)
names(titanic.dt)
head(titanic.dt)
titanic.dt$survived <- as.factor(titanic.dt$survived)
#15세 미만을 아이로 본다.
titanic.dt[,isminor:="adult"]
titanic.dt[age < 15,isminor:="child"]
titanic.dt$isminor <- as.factor(titanic.dt$isminor)
# 등급별 생존률
titanic.dt[, length(which(survived == 1))/nrow(.SD), by=pclass]
# 성별 생존률
titanic.dt[, length(which(survived == 1))/nrow(.SD), by=sex]
#등급/성별 생존률
survived_pclass_sex <- titanic.dt[, list(cntsurv=length(which(survived == 1)), cntdie=length(which(survived == 0))),
by=list(pclass, sex)][,list(psurvived=cntsurv/(cntsurv + cntdie)),by=list(pclass, sex)]
ggplot(survived_pclass_sex, aes(pclass, sex)) +
geom_tile(aes(fill=psurvived)) + scale_fill_gradient2("생존률") + xlab("승객등급") + ylab("성별")
#성별, 등급, 나이별 생존률
survived_pclass_sex_isminor<- titanic.dt[,list(cntsurv=length(which(survived == 1)), cntdie=length(which(survived == 0))),by=list(pclass, sex, isminor)][,list(psurvived=cntsurv/(cntsurv + cntdie)),by=list(pclass, sex, isminor)]
survived_pclass_sex_isminor$sex_age <- apply(survived_pclass_sex_isminor[,list(sex,isminor)], 1, paste, collapse="_")
library(scales)
ggplot(survived_pclass_sex_isminor, aes(pclass, sex_age)) +
geom_tile(aes(fill=psurvived)) + scale_fill_gradient2("생존률", low=muted("white"), high=muted("blue")) + xlab("승객등급") + ylab("성별과 나이")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
url <- function(address, return.call = "json", sensor = "false") {
root <- "http://maps.google.com/maps/api/geocode/"
u <- paste(root, return.call, "?address=", address,   "&sensor=", sensor, sep = "")
return(URLencode(u))
}
geoCode <- function(address,verbose=FALSE) {
u <- url(address)
doc <- getURL(u)
x <- fromJSON(doc,simplify = FALSE)
lat <- x$results[[1]]$geometry$location$lat
lng <- x$results[[1]]$geometry$location$lng
}
url("Seoul")
geoCode(url("Seoul"))
geoCode("Seoul")
ls
ls()
View(titanic.dt)
View(titanic)
install.packages("testthat")
source('~/.active-rstudio-document', echo=TRUE)
install.packages('gridExtra')
install.packages('corrplot')
install.packages('GGally')
install.packages('ggplot2')
install.packages("ggplot2")
install.packages('e1071')
install.packages('dplyr')
install.packages("dplyr")
source('~/.active-rstudio-document', echo=TRUE)
source('~/Desktop/3-1/DataMining/EDAreferenceCode/readme_script2.R', echo=TRUE)
train <- fread('train.csv',colClasses=c('MiscFeature' = "character", 'PoolQC' = 'character', 'Alley' = 'character'))
test <- fread('test.csv' ,colClasses=c('MiscFeature' = "character", 'PoolQC' = 'character', 'Alley' = 'character'))
library(purrr)
vignette("databases", package = "dplyr")
install.packages("Lahman")
system('defaults write org.R-project.R force.LANG en_US.UTF-8')
install.packages("Lahman")
?tally
?summarize
?summarise
?summarize
??summarize
library(dplyr)
?summarize
?bind_rows
?distinct
?left_join
?group_by
by_cyl <- mtcars %>% group_by(cyl)
View(by_cyl)
View(by_cyl)
car <- mtcars
View(car)
View(car)
?join
?join
?semi_join
library(dplyr)
?join
install.packages("MASS")
library(MASS)
plot(mtcars)
?points
install.packages()
install.packages("car")
library(car)
str(mtcars)
mtcars %>%
select(mpg, cyl, hp)
mtcars %>%
select("mpg", "cyl", "hp")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
mtcars %>%
select(mpg, cyl, hp)
?select
library(dplyr)
mtcars %>%
select(mpg, cyl, hp)
?select
mtcars %>%
select(mpg)
mtcars %>%
select(mpg)
mtcars %>%
select(mtcars$mpg)
mtcars %>%
select(.data$mpg)
select(mtcars, .data$cyl)
mtcars
mtcars %>%
select(mpg)
mtcars %>%
select(mpg)
mtcars
select(mtcars, mpg, cyl)
library(dplyr)
select(mtcars, mpg, cyl)
mtcars %>%
select(mpg, cyl, hp)
source('~/.active-rstudio-document', echo=TRUE)
carData <- mtcars %>%
select(mpg, cyl, hp)
source('~/.active-rstudio-document', echo=TRUE)
library(dplyr, ggplot2)
?ggplot2
boxplot(carData)
lm(carData)
hist(lm(carData))
plot(carData)
head(carData)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
class(cyl4)
?sapply
cylall <- list(cyl4, cyl6, cyl8)
lapply(cylall, mean)
cylall
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
cbind(mean(cyl4), mean(cyl6), mean(cyl8 ))
cyl4
cbind(mean(cyl4$hp), mean(cyl6$hp), mean(cyl8$hp))
?tapply
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$mpg, mtcars$hp, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
cbind(mean(cyl4$hp), mean(cyl6$hp), mean(cyl8$hp))
plot(mtcars$hp, mtcars$cyl)
plot(mtcars$cyl,mtcars$hp)
plot(mtcars$cyl,mtcars$mpg)
plot(mtcars$hp,mtcars$mpg)
plot(mtcars$hp ~ mtcars$mpg)
?glm
counts <- c(18,17,15,20,10,20,25,13,12)
outcome <- gl(3,1,9)
treatment <- gl(3,3)
print(d.AD <- data.frame(treatment, outcome, counts))
glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
anova(glm.D93)
summary(glm.D93)
### Add more variable...
modelcv4 <- train(Price ~ Age_08_04 + KM + HP + Met_Color + Automatic + CC
+ Doors + Quarterly_Tax, data = carData,  method = "lm",
trControl = trainControl(method = "cv", number = 5,verboseIter = TRUE))
gl(3,1,9)
?gl
outcome
treatment
?predict
?ifelse
?confusionMatrix
library(caret)
?confusionMatrix
?trainControl
?train
?tuneLength
?twoClassSummary
?classProbs
?trainControl
?twoClassSummary
?preProcess
?createFolds
?train
?resamples
?knn
library(class)
?table
library(naivebaye)
install.packages("naivebayes")
library(naivebaye)
library(naivebayes)
install.packages("pROC")
library(pROC)
?relevel
source('~/Desktop/3-1/DataMining/HW1/HW1.R', echo=TRUE)
source('~/Desktop/3-1/DataMining/HW1/HW1.R', echo=TRUE)
modelcv1
predict1
rsquared_error1
rsquared_error1
rsquared_error1 <- 1 - sum(error1^2)/sstot_error1
rsquared_error1
modelcv1
(rsquared_error4 <- 1 - sum(error4^2)/sstot_error)
source('~/Desktop/3-1/DataMining/HW1/HW1.R', echo=TRUE)
source('~/Desktop/3-1/DataMining/HW1/HW1.R', echo=TRUE)
tot_error
sstot_error
source('~/Downloads/HW1 2/HW1.R', echo=TRUE)
?model.matrix
?gather
# get first observation for each Species in iris data -- base R
mini_iris <- iris[c(1, 51, 101), ]
mini_iris
# gather Sepal.Length, Sepal.Width, Petal.Length, Petal.Width
gather(mini_iris, key = flower_att, value = measurement,
Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)
# repeat iris example using dplyr and the pipe operator
library(dplyr)
# gather Sepal.Length, Sepal.Width, Petal.Length, Petal.Width
gather(mini_iris, key = flower_att, value = measurement,
Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)
library(dplyr)
# get first observation for each Species in iris data -- base R
mini_iris <- iris[c(1, 51, 101), ]
# gather Sepal.Length, Sepal.Width, Petal.Length, Petal.Width
gather(mini_iris, key = flower_att, value = measurement,
Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)
# same result but less verbose
gather(mini_iris, key = flower_att, value = measurement, -Species)
library(tidyr)
# gather Sepal.Length, Sepal.Width, Petal.Length, Petal.Width
gather(mini_iris, key = flower_att, value = measurement,
Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)
# get first observation for each Species in iris data -- base R
mini_iris <- iris[c(1, 51, 101), ]
mini_iris
# same result but less verbose
gather(mini_iris, key = flower_att, value = measurement, -Species)
mini_iris
head(iris)
mini_iris <-
iris %>%
group_by(Species)
mini_iris
head(iris, 30)
mini_iris <-
iris %>%
group_by(Species) %>%
slice(1)
mini_iris
mini_iris %>% gather(key = flower_att, value = measurement, -Species)
tail(iris)
tail(mini_iris)
?I
?kWayCrossValidation
?paste
?ranger
librar(ranger)
library(ranger)
library(rpart)
?ranger
install.packages("ranger")
library(ranger)
?ranger
?kmeans
?elbow
?apply
?prcomp
?prcomp
?apply
source('~/Desktop/CancerAnalysis.R', echo=TRUE)
?grepl
source('~/Desktop/CancerAnalysis.R', echo=TRUE)
source('~/Desktop/CancerAnalysis.R', echo=TRUE)
source('~/Desktop/CancerAnalysis.R', echo=TRUE)
rm
rm()
ls
ls()
rm()
ls
ls()
rm(ls())
rm(as.list(ls()))
source('~/Desktop/CancerAnalysis.R', echo=TRUE)
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
# Download the data: wisc.df
wisc.df <- read.csv(url)
# Convert the features of the data: wisc.data
wisc.data <- as.matrix(wisc.df[3:32])
class(wisc.df)
# Set the row names of wisc.data
row.names(wisc.data) <- wisc.df$id
# Create diagnosis vector
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
View(wisc.data)
View(wisc.df)
## EDA
str(wisc.data) # How many observations are in this dataset?
sum(grepl(pattern = "_mean", colnames(wisc.data))) # How many variables/features in the data are suffixed with _mean?
sum(diagnosis == 1) # How many of the observations have a malignant diagnosis?
## PCA
# Check column means and standard deviations
colMeans(wisc.data)
apply(wisc.data, 2, sd)
# Execute PCA, scaling if appropriate: wisc.pr
wisc.pr <- prcomp(wisc.data, scale = TRUE)
View(wisc.pr)
wisc.pr[["rotation"]]
wisc.pr[["x"]]
# Look at summary of results
summary(wisc.pr)
# Create a biplot of wisc.pr
biplot(wisc.pr)
par(mfrow = c(1, 2))
# Scatter plot observations by components 1 and 2
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
# Repeat for components 1 and 3
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
par(mfrow = c(1, 2))
# Scatter plot observations by components 1 and 2
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
title("PC2 ~ PC1")
# Repeat for components 1 and 3
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
title("PC3 ~ PC1")
# Scree plot
# Set up 1 x 2 plotting grid
par(mfrow = c(1, 2))
# Calculate variability of each component
pr.var <- wisc.pr$sdev^2
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)
# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Scree plot
# Set up 1 x 2 plotting grid
par(mfrow = c(1, 2))
# Calculate variability of each component
pr.var <- wisc.pr$sdev^2
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)
title("Scree plot")
# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Plot cumulative proportion of variance explained
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Scree plot
# Set up 1 x 2 plotting grid
par(mfrow = c(1, 2), main = "Scree plot")
?par
# Scree plot
# Set up 1 x 2 plotting grid
par(mfrow = c(1, 2))
# Calculate variability of each component
pr.var <- wisc.pr$sdev^2
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)
# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Plot cumulative proportion of variance explained
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# For the first principal component,
# what is the component of the loading vector for the feature concave.points_mean?
# PC1에 대해서 변형되기 전의 concave.points_mean 축은 얼마인가?(내 추측...)
wisc.pr$rotation["concave.points_mean", "PC1"]
# What is the minimum number of principal components required
# to explain 80% of the variance of the data?
cumsum(pve)
# Scale the wisc.data data: data.scaled
data.scaled <- scale(wisc.data)
# Calculate the (Euclidean) distances: data.dist
data.dist <- dist(data.scaled)
# Create a hierarchical clustering model: wisc.hclust
wisc.hclust <- hclust(data.dist, method = "complete")
# Cut tree so that it has 4 clusters: wisc.hclust.clusters
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
plot(wisc.hclust.clusters)
plot(wisc.hclust)
plot(wisc.hclust)
plot(wisc.hclust)
# Compare cluster membership to actual diagnoses
table(diagnosis, wisc.hclust.clusters)
## Create a k-means model on wisc.data: wisc.km
wisc.km <- kmeans(scale(wisc.data), centers = 2, nstart = 20)
# Compare k-means to actual diagnoses
table(diagnosis, wisc.km$cluster)
# Compare k-means to hierarchical clustering
table(wisc.hclust.clusters, wisc.km$cluster)
# Compare k-means to hierarchical clustering
plot(table(wisc.hclust.clusters, wisc.km$cluster))
# Compare k-means to actual diagnoses
plot(table(diagnosis, wisc.km$cluster))
# Compare k-means to hierarchical clustering
table(wisc.hclust.clusters, wisc.km$cluster)
# Create a hierarchical clustering model: wisc.pr.hclust
# (Using the minimum number of principal components required
# to describe at least 90% of the variability in the data,
# create a hierarchical clustering model with complete linkage.
# Assign the results to wisc.pr.hclust.)
summary(wisc.pr) # PC7에서 91%
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method = "complete")
# Cut model into 4 clusters: wisc.pr.hclust.clusters
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k = 4)
# Compare to actual diagnoses
table(diagnosis, wisc.pr.hclust.clusters)
# Compare to k-means and hierarchical
table(diagnosis, wisc.hclust.clusters)
table(diagnosis, wisc.km$cluster)
